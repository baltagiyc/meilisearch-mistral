# Test results — 43 chunks & 10k docs

Single reference for all measured results. Scripts and details: [BILAN.md](BILAN.md).

---

## 1. Index: 43 chunks (`pdf_chunks`)

Source: `mistral-doc.pdf` → pipeline → 43 chunks. Index: `pdf_chunks`.

### Search latency (50 requests, query *"architecture Mixtral experts routing"*)

| Metric | Keyword-only | Hybrid |
|--------|--------------|--------|
| **Mean** | 3 ms | 335 ms |
| **p50** | 2 ms | 194 ms |
| **p95** | 9 ms | 727 ms |

- **Keyword**: `audit/benchmark_keyword_latency.py` — full-text only, no embedder.
- **Hybrid**: `audit/benchmark_hybrid_latency.py` — same as chat (semanticRatio 0.5, embedder mistral).

---

## 2. Index: 10k docs (`pdf_chunks_scale`)

Source: 43 chunks cloned to 10 000 docs (scale test). Index: `pdf_chunks_scale`.

### Ingestion

| Metric | Value |
|--------|--------|
| **Total time** | 776.9 s |
| **Throughput** | 12.9 docs/s |
| **Batches** | 10 × 1000 docs |

- Script: `scale_test/run_scale_test.py` (initial settings ~533 s excluded from total).

### Search latency (50 requests, same query)

| Metric | Value |
|--------|--------|
| **Mean** | 758 ms |
| **p50** | 206 ms |
| **p95** | 2997 ms |

---

## 3. Comparison (43 chunks vs 10k docs)

### Hybrid search latency (ms)

| Metric | 43 chunks | 10k docs |
|--------|-----------|----------|
| **Mean** | 335 | 758 |
| **p50** | 194 | 206 |
| **p95** | 727 | 2997 |

### Ingestion

| | 43 chunks | 10k docs |
|---|-----------|----------|
| **Time** | ~2 s (1 batch) | 776.9 s |
| **Throughput** | ~21 docs/s | 12.9 docs/s |

---

## 4. Charts

- **Comparison (latency + throughput):**  
  [scale_test/scale_comparison.png](scale_test/scale_comparison.png) · [scale_test/scale_comparison.svg](scale_test/scale_comparison.svg)  
  Generated by: `uv run python complex_pdf_test/scale_test/plot_scale_comparison.py`

---

## 5. How to re-run

| Result | Command |
|--------|--------|
| 43 chunks — keyword | `uv run python complex_pdf_test/audit/benchmark_keyword_latency.py` |
| 43 chunks — hybrid | `uv run python complex_pdf_test/audit/benchmark_hybrid_latency.py` |
| 10k — ingestion + hybrid | `uv run python complex_pdf_test/scale_test/run_scale_test.py` |
| Charts | `uv run python complex_pdf_test/scale_test/plot_scale_comparison.py` |

All from project root. Meilisearch + `.env` (MISTRAL_API_KEY, etc.) required.
